{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerie utili \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests #Pushshift accede a reddit attraverso un URL \n",
    "import json \n",
    "import csv \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene definita una funzione chiamata getData, la quale costruisce un Pushfit URL, accede alla webpage e archivia tutti i dati JSON e ritorna l'elemento data che contiene tutti i dati relativi ad una submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list\n",
    "def getData(query1,query2, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query1)+'|'+str(query2)+'&size=100&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene definita la funzione collectData che ha il compito di estrarre i principali dati da ogni risultato JSON ottenuto dalla funzione getData, i quali vengono prima inseriti in una lista per poi venire memorizzati in un dizionario che ha come chiave il sub_id (identificativo univoco della submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collectData(subm):\n",
    "    \n",
    "    subData = list() \n",
    "    title = subm['title']\n",
    "    url = subm['url']\n",
    "    #try:\n",
    "       # body=subm['selftext']\n",
    "    #except KeyError:\n",
    "        #body='Nan'\n",
    "    \n",
    "       \n",
    "    #flairs are not always present so we wrap in try/except\n",
    "    #try:\n",
    "        #flair = subm['link_flair_text']\n",
    "    #except KeyError:\n",
    "        #flair = \"NaN\"    \n",
    "    author = subm['author']\n",
    "    sub_id = subm['id']\n",
    "    score = subm['score']\n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc']) # la data viene trasformata da timestamp in datetime\n",
    "    numComms = subm['num_comments']\n",
    "    subData.append((sub_id,title,url,author,score,created,numComms))\n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definire il periodo temporale d'interesse, le parole chiave da ricercare e il subreddit in cui cercare. Viene poi definita una variabile contatore che permette di contare il numero totale di submission che abbiamo raccolta e viene definito il dizionario in cui verranno conservati i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning_timestamp = int(datetime.datetime(year=2021, month=1, day=11).timestamp())\n",
    "end_timestamp = int(datetime.datetime(year=2021, month=2, day=4).timestamp())\n",
    "after = beginning_timestamp\n",
    "before = end_timestamp\n",
    "query1 = \"GME\" # le query non sono case-sensitive\n",
    "query2='GameStop'\n",
    "\n",
    "sub = \"wallstreetbets\" \n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo script permette di fare più richieste all'api di Reddit attraverso la funzione GetData, fichè il valore di after e before non diventano lo stesso. Per ogni richiesta la data viene aggiornata con la data dell'ultima submission scaricata dalla precedente richiesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene dato un po' di context per vedere meglio effettivamente se quello che è stato scaricato è giusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 submissions aggiunte alla lista\n",
      "La prima submission è:\n",
      "70% SPIKE, gme 🚀🚀🚀🚀 creata: 2021-01-11 00:19:52\n",
      "Last entry is:\n",
      "My Hinge Dating Match 😳 works in Finances 📈 and her DD says GME 🎮 is going higher! 🚀🚀🚀 Throw some moon rocks at those gay bears!!! 🌈🐻 Diamonds Hands ! 💎👐 creata: 2021-01-14 08:47:32\n"
     ]
    }
   ],
   "source": [
    "print(str(len(subStats)) + \" submissions aggiunte alla lista\")\n",
    "print(\"La prima submission è:\")\n",
    "print(list(subStats.values())[0][0][1] + \" creata: \" + str(list(subStats.values())[0][0][5]))\n",
    "print(\"Last entry is:\")\n",
    "print(list(subStats.values())[-1][0][1] + \" creata: \" + str(list(subStats.values())[-1][0][5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tramite questa funzione i dati collezionati nel dizionario in un formato JSON vengono trasformati in un dataset in formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtocsv():\n",
    "    upload_count = 0\n",
    "    print(\"input filename of submission file, please add .csv\")\n",
    "    filename = input() # viene chiesto all'utenete di nominare il file\n",
    "    file = filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = [\"Post ID\",\"Title\",\"Url\",\"Body\",\"Author\",\"Score\",\"Publish Date\",\"Total No. of Comments\"]\n",
    "        a.writerow(headers)\n",
    "        for sub in subStats:\n",
    "            a.writerow(subStats[sub][0])\n",
    "            upload_count+=1\n",
    "            \n",
    "        print(str(upload_count) + \" submissions have been uploaded\")\n",
    "subtocsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
